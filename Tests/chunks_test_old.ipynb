{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dtgLxkQBVU4",
        "outputId": "6b4302f6-0069-42e5-8887-3b47b613f422"
      },
      "outputs": [],
      "source": [
        "# !pip install purecpp_extract purecpp_chunks_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Id24_ARrT_KY"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/PureAI-Tools/Tests.git # comentar isso no jupiter local \n",
        "#API_KEY = \"\"\n",
        "# import os\n",
        "# os.environ[\"...\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TAd_tzUZBVU5"
      },
      "outputs": [],
      "source": [
        "import purecpp_extract as ext\n",
        "import purecpp_chunks_clean as cc\n",
        "from purecpp_libs import DataExtractRequestStruct, LoaderDataStruct, RAGDocument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UZD-yrgDBVU5"
      },
      "outputs": [],
      "source": [
        "pdf_loader = ext.PDFLoader()\n",
        "pdf_loader2 = ext.PDFLoader()\n",
        "pdf_loader3 = ext.PDFLoader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bQJYoK9vBVU5"
      },
      "outputs": [],
      "source": [
        "docxLoader = ext.DOCXLoader()\n",
        "docxLoader2 = ext.DOCXLoader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hetDV2BWBVU5",
        "outputId": "98784087-4e9f-480d-f275-030e0949d007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content : \n",
            " None\n",
            "IsRegularFile: pdfs/1984.pdf\n",
            "IsRegularFile: pdfs/a-christmas-carol.pdf\n",
            "Number of pages: 393\n",
            "Number of pages: 106\n"
          ]
        }
      ],
      "source": [
        "var = pdf_loader.InsertDataToExtract([\n",
        "        DataExtractRequestStruct(\"pdfs/1984.pdf\"),\n",
        "        DataExtractRequestStruct(\"pdfs/a-christmas-carol.pdf\"),\n",
        "    ]) # No jupiter ta imprimindo q tao sendo achados arquivos aqui n\n",
        "print(f\"Content : \\n {var}\") # Poderia..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zDJhPHARBVU6"
      },
      "outputs": [],
      "source": [
        "# pdf_loader2.InsertDataToExtract([DataExtractRequestStruct(\"pdfs\")]) # deveria dar erro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oSTt3r20BVU6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IsRegularFile: pdfs/1984.pdf\n",
            "Number of pages: 393\n"
          ]
        }
      ],
      "source": [
        "pdf_loader3.InsertDataToExtract([DataExtractRequestStruct(\"pdfs/1984.pdf\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "J1VwPoL0BVU6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IsRegularFile: docxs/sample1.docx\n",
            "IsRegularFile: docxs/sample4.docx\n"
          ]
        }
      ],
      "source": [
        "docxLoader.InsertDataToExtract([\n",
        "        DataExtractRequestStruct(\"docxs/sample1.docx\"),\n",
        "        DataExtractRequestStruct(\"docxs/sample4.docx\")\n",
        "    ]) # Tem que avisar que n encontra a pasta ou o arquivo na pasta se n o encontrar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rydW1EdIBVU6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IsRegularFile: docxs/sample4.docx\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IsRegularFile: docxs/teste-2020-07.docx\n",
            "IsRegularFile: docxs/sample1.docx\n"
          ]
        }
      ],
      "source": [
        "docxLoader2.InsertDataToExtract([DataExtractRequestStruct(\"docxs\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3NCE2x2BVU6",
        "outputId": "3cbbc2ae-3545-4648-dc24-6646af1f800b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Download free eBooks of classic literature, books and \\r\\nnovels at Planet eBook. Subscribe to our free eBooks blog \\r\\nand email newsletter.\\r\\n1984\\r\\nBy George Orwell']\n",
            "\n",
            "\n",
            "['\\x18 1984\\r\\nPart One']\n",
            "\n",
            "\n",
            "['Free eBooks at Planet eBook.com \\x18\\r\\nChapter 1\\r\\nI\\r\\nt was a bright cold day in April, and the clocks were strik\\x02ing thirteen. Winston Smith, his chin nuzzled into his \\r\\nbreast in an effort to escape the vile wind, slipped quickly \\r\\nthrough the glass doors of Victory Mansions, though not \\r\\nquickly enough to prevent a swirl of gritty dust from enter\\x02ing along with him.\\r\\nThe hallway smelt of boiled cabbage and old rag mats. At \\r\\none end of it a coloured poster, too large for indoor display, \\r\\nhad been tacked to the wall. It depicted simply an enor\\x02mous face, more than a metre wide: the face of a man of \\r\\nabout forty-five, with a heavy black moustache and rugged\\x02ly handsome features. Winston made for the stairs. It was \\r\\nno use trying the lift. Even at the best of times it was sel\\x02dom working, and at present the electric current was cut \\r\\noff during daylight hours. It was part of the economy drive \\r\\nin preparation for Hate Week. The flat was seven flights up, \\r\\nand Winston, who was thirty-nine and had a varicose ulcer \\r\\nabove his right ankle, went slowly, resting several times on \\r\\nthe way. On each landing, opposite the lift-shaft, the poster \\r\\nwith the enormous face gazed from the wall. It was one of \\r\\nthose pictures which are so contrived that the eyes follow \\r\\nyou about when you move. BIG BROTHER IS WATCHING \\r\\nYOU, the caption beneath it ran.\\r\\nInside the flat a fruity voice was reading out a list of fig-']\n",
            "\n",
            "\n",
            "393 Pages\n"
          ]
        }
      ],
      "source": [
        "opt_struct = pdf_loader.GetTextContent(\"1984\") # N retorna um tipo string\n",
        "text_content = str(opt_struct)\n",
        "text_content_limited = text_content[:100]\n",
        "# print(text_content_limited)\n",
        "for i in range(3):\n",
        "  print(opt_struct.textContent[i:i+1])\n",
        "  print(\"\\n\")\n",
        "\n",
        "print(f\"{len(opt_struct.textContent)} Pages\")# Isso salva como paginas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'purecpp_libs.LoaderDataStruct'>\n",
            "__class__\n",
            "__delattr__\n",
            "__dir__\n",
            "__doc__\n",
            "__eq__\n",
            "__format__\n",
            "__ge__\n",
            "__getattribute__\n",
            "__getstate__\n",
            "__gt__\n",
            "__hash__\n",
            "__init__\n",
            "__init_subclass__\n",
            "__le__\n",
            "__lt__\n",
            "__module__\n",
            "__ne__\n",
            "__new__\n",
            "__reduce__\n",
            "__reduce_ex__\n",
            "__repr__\n",
            "__setattr__\n",
            "__sizeof__\n",
            "__str__\n",
            "__subclasshook__\n",
            "_pybind11_conduit_v1_\n",
            "metadata\n",
            "textContent\n",
            "<class 'list'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(type(opt_struct))\n",
        "for item in dir(opt_struct):\n",
        "    print(item)\n",
        "print(type(dir(opt_struct)))\n",
        "# help(opt_struct)\n",
        "type(opt_struct.textContent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv67-1GGJAu0",
        "outputId": "5321a39a-84f9-4c5a-8028-c5d7f90b5bf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_pybind11_conduit_v1_: <bound method PyCapsule._pybind11_conduit_v1_ of <purecpp_libs.LoaderDataStruct object at 0x7f427c2027b0>>\n",
            "----------------------------------------------\n",
            "metadata: {'fileIdentifier': '1984'}\n",
            "----------------------------------------------\n",
            "textContent: Is a list of 393 Pages\n",
            "Page 0 textContent :\n",
            "Download free eBooks of classic literature, books and \n",
            "novels at Planet eBook. Subscribe to our free eBooks blog \n",
            "and email newsletter.\n",
            "1984\n",
            "By George Orwell \n",
            "----------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for attr_name in dir(opt_struct):\n",
        "    if not attr_name.startswith(\"__\"):  # Ignora atributos internos\n",
        "        try:\n",
        "            value = getattr(opt_struct, attr_name)\n",
        "            if attr_name == \"textContent\":\n",
        "                print(f\"{attr_name}: Is a list of {len(value)} Pages\")\n",
        "                print(f\"Page 0 {attr_name} :\\n{value[0]} \")\n",
        "            else:\n",
        "              print(f\"{attr_name}: {value}\")\n",
        "            print(\"----------------------------------------------\")\n",
        "        except AttributeError:\n",
        "            print(f\"{attr_name}: [não acessível]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6UQu19NBVU6",
        "outputId": "66540bd6-206c-4f77-8ba4-1e93284e8c0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<purecpp_libs.LoaderDataStruct at 0x7f427c201d30>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_loader.GetTextContent(\"1984\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPEMKujoOspw",
        "outputId": "c9b9674d-76a0-41ad-f995-e097041de9a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deu erro\n"
          ]
        }
      ],
      "source": [
        "if not pdf_loader3.GetTextContent(\"a-christmas-carol\"): # DEVERIA DAR ERRO\n",
        "    print(\"deu erro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9QBx5UpKBVU7"
      },
      "outputs": [],
      "source": [
        "pdf_loader3.GetTextContent(\"sdauhdsahudsauhdsahuds\") # DEVERIA DAR ERRO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mfJHH8uJP84r"
      },
      "outputs": [],
      "source": [
        "# print(type(pdf_loader))\n",
        "# for item in dir(pdf_loader):\n",
        "#     print(item)\n",
        "# print(type(dir(pdf_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bxGLAn7iSqOi"
      },
      "outputs": [],
      "source": [
        "# help(pdf_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5b8RLZ8BVU7",
        "outputId": "0c420109-123b-4b20-fb52-d533e06b3599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de documentos carregados: 2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "items_docx = []\n",
        "\n",
        "for fname in [\"sample1\", \"sample4\"]: # poderia ter um metodo para recuperar as listas naquela List de LoaderDataStruct < --------------- >\n",
        "    x = docxLoader.GetTextContent(fname)\n",
        "    if x:\n",
        "        items_docx.append(x.textContent)  # cada item é um List em LoaderDataStruct\n",
        "    else:\n",
        "        print(f\"Não foi possível extrair: {fname}\")\n",
        "if not items_docx:\n",
        "        print(\"Nenhum documento foi carregado com sucesso! Encerrando.\")\n",
        "print(f\"Total de documentos carregados: {len(items_docx)}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRrzy5w2BVU7",
        "outputId": "d9c7d506-b274-4798-acf6-c10dc474c0c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de documentos carregados: 2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "items = []\n",
        "item_struct =  []\n",
        "\n",
        "for fname in [\"1984\", \"a-christmas-carol\"]: # poderia ter um metodo para recuperar as listas naquela List de LoaderDataStruct < --------------- >\n",
        "    opt_struct = pdf_loader.GetTextContent(fname)\n",
        "    if opt_struct:\n",
        "        items.append(opt_struct.textContent)   # cada item é um List em LoaderDataStruct\n",
        "        item_struct.append(opt_struct) # cada item é LoaderDataStruct\n",
        "    else:\n",
        "        print(f\"Não foi possível extrair: {fname}\")\n",
        "if not items:\n",
        "        print(\"Nenhum documento foi carregado com sucesso! Encerrando.\")\n",
        "print(f\"Total de documentos carregados: {len(items)}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWxrWtxABVU7",
        "outputId": "89a8b0c8-45c6-43e8-9f0a-19c4aaa3adf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------------------------------\n",
            "--- LoaderDataStruct nº 0 ---\n",
            ">> METADATA:\n",
            "   fileIdentifier => 1984\n",
            "\n",
            ">> TEXT CONTENT=> Free eBooks at Planet eBook.com 11\n",
            "er of expressing himself, but even to have forgotten what it \n",
            "w ...\n",
            "\n",
            "--- LoaderDataStruct nº 1 ---\n",
            ">> METADATA:\n",
            "   fileIdentifier => a-christmas-carol\n",
            "\n",
            ">> TEXT CONTENT=> Free eBooks at Planet eBook.com 11\n",
            "‘Under the impression that they scarcely furnish Chris\u0002tian chee ...\n",
            "\n",
            "---------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(\"---------------------------------------------------------\")\n",
        "for i, lds in enumerate(item_struct):\n",
        "    print(f\"--- LoaderDataStruct nº {i} ---\")\n",
        "\n",
        "    print(\">> METADATA:\")\n",
        "    for mk, mv in lds.metadata.items():\n",
        "        print(f\"   {mk} => {mv}\")\n",
        "\n",
        "    print(f\"\\n>> TEXT CONTENT=> {lds.textContent[10][:100]} ...\")\n",
        "    print()\n",
        "print(\"---------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FULkiChjBVU7"
      },
      "outputs": [],
      "source": [
        "# 2) CHUNKANDO COM ChunkDefault\n",
        "#    (divide texto em blocos de 300 chars, com overlap=50)\n",
        "# default_chunker = cc.ChunkDefault(chunk_size=300, overlap=50)\n",
        "default_chunker = cc.ChunkDefault(50, 10) # poderia passar o item ja aqui\n",
        "default_chunker2 = cc.ChunkDefault(50, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wAFR3RUpBVU7"
      },
      "outputs": [],
      "source": [
        "# std::vector<RAGLibrary::Document> ProcessSingleDocument(RAGLibrary::LoaderDataStruct &item);\n",
        "default_docs = default_chunker.ProcessData(item_struct[0])\n",
        "# std::vector<RAGLibrary::Document> ProcessDocuments(const std::vector<RAGLibrary::LoaderDataStruct> &items, int max_workers = 4);\n",
        "default_docs2 = default_chunker2.ProcessData(item_struct, max_workers=2) # Tem q ser uma lista de purecpp_libs.purecpp_libs.LoaderDataStruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjA8yE8jBVU8",
        "outputId": "cf4f33dd-ac4c-4fd4-82a2-a8991c17e358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChunkDefault(50, 10) from  documents.size=15493\n",
            "ChunkDefault(50, 10) from  documents.size=19616\n"
          ]
        }
      ],
      "source": [
        "print(f\"ChunkDefault(50, 10) from  documents.size={len(default_docs)}\")\n",
        "print(f\"ChunkDefault(50, 10) from  documents.size={len(default_docs2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iduy2eP_OHqY"
      },
      "outputs": [],
      "source": [
        "# print(type(default_docs[0])) # purecpp_libs.purecpp_libs.RAGDocument\n",
        "# for item in dir(default_docs[0]):\n",
        "#     print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "STSz0CSLOg_c"
      },
      "outputs": [],
      "source": [
        "# default_docs[0]\n",
        "# help(default_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ily7TuhZBVU8",
        "outputId": "617a780f-0eeb-40fb-868b-8d58cc56f175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "default\n",
            "Primeiro [0] METADATA => {'fileIdentifier': '1984'}\n",
            "Primeiro [1] METADATA => {'fileIdentifier': '1984'}\n",
            "Primeiro [2] METADATA => {'fileIdentifier': '1984'}\n",
            "Último [15490] METADATA => {'fileIdentifier': '1984'}\n",
            "Último [15491] METADATA => {'fileIdentifier': '1984'}\n",
            "Último [15492] METADATA => {'fileIdentifier': '1984'}\n",
            "-----------------------------------------------------------------------------------------\n",
            "default 2\n",
            "Primeiro [0] METADATA => {'fileIdentifier': 'a-christmas-carol'}\n",
            "Primeiro [1] METADATA => {'fileIdentifier': 'a-christmas-carol'}\n",
            "Primeiro [2] METADATA => {'fileIdentifier': 'a-christmas-carol'}\n",
            "Último [19613] METADATA => {'fileIdentifier': '1984'}\n",
            "Último [19614] METADATA => {'fileIdentifier': '1984'}\n",
            "Último [19615] METADATA => {'fileIdentifier': '1984'}\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"-----------------------------------------------------------------------------------------\")\n",
        "print(\"default\")\n",
        "list_default_docs = []\n",
        "# Garantir que temos ao menos 3 elementos\n",
        "n = len(default_docs)\n",
        "first_n = default_docs[:3]            # primeiros 3\n",
        "last_n = default_docs[-3:] if n >= 3 else []  # últimos 3 (sem repetir os primeiros)\n",
        "# Adiciona os page_content dos primeiros\n",
        "for i, doc in enumerate(first_n):\n",
        "    print(f\"Primeiro [{i}] METADATA =>\", doc.metadata)\n",
        "    list_default_docs.append(doc.page_content)\n",
        "# Adiciona os page_content dos últimos\n",
        "for i, doc in enumerate(last_n):\n",
        "    print(f\"Último [{n - 3 + i}] METADATA =>\", doc.metadata)\n",
        "    list_default_docs.append(doc.page_content)\n",
        "\n",
        "print(\"-----------------------------------------------------------------------------------------\")\n",
        "print(\"default 2\")\n",
        "list_default_docs2 = []\n",
        "# Garantir que temos ao menos 3 elementos\n",
        "n = len(default_docs2)\n",
        "first_n = default_docs2[:3]            # primeiros 3\n",
        "last_n = default_docs2[-3:] if n >= 3 else []  # últimos 3 (sem repetir os primeiros)\n",
        "# Adiciona os page_content dos primeiros\n",
        "for i, doc in enumerate(first_n):\n",
        "    print(f\"Primeiro [{i}] METADATA =>\", doc.metadata)\n",
        "    list_default_docs2.append(doc.page_content)\n",
        "# Adiciona os page_content dos últimos\n",
        "for i, doc in enumerate(last_n):\n",
        "    print(f\"Último [{n - 3 + i}] METADATA =>\", doc.metadata)\n",
        "    list_default_docs2.append(doc.page_content)\n",
        "print(\"-----------------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 0:  Download free eBooks of classic literature, books  ...\n",
            " 1:  re, books and \n",
            "novels at Planet eBook. Subscribe  ...\n",
            " 2:  Subscribe to our free eBooks blog \n",
            "and email news ...\n",
            " 3:  inary work \n",
            "of translation that the final adoptio ...\n",
            " 4:  al adoption of Newspeak had been \n",
            "fixed for so la ...\n",
            " 5:   for so late a date as 2050. ...\n",
            "-----------------------------------------------------------------------------------------\n",
            " 0:  Download free eBooks of classic literature, books  ...\n",
            " 1:  re, books and \n",
            "novels at Planet eBook. Subscribe  ...\n",
            " 2:  Subscribe to our free eBooks blog \n",
            "and email news ...\n",
            " 3:  inary work \n",
            "of translation that the final adoptio ...\n",
            " 4:  al adoption of Newspeak had been \n",
            "fixed for so la ...\n",
            " 5:   for so late a date as 2050. ...\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i, doc in enumerate(list_default_docs):\n",
        "    print(f\" {i}:  {doc} ...\")\n",
        "print(\"-----------------------------------------------------------------------------------------\")\n",
        "\n",
        "for i, doc in enumerate(list_default_docs2):\n",
        "    print(f\" {i}:  {doc} ...\")\n",
        "print(\"-----------------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Não foi possível gerar embeddings com OpenAI (talvez sem chave válida): {\"code\":\"invalid_api_key\",\"message\":\"Incorrect API key provided: sk-proj-********************************************************************************************************************************************************SkkA. You can find your API key at https://platform.openai.com/account/api-keys.\",\"param\":null,\"type\":\"invalid_request_error\"}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    openai_emb = cc.EmbeddingOpeanAI(\n",
        "        list_default_docs, \n",
        "        API_KEY,\n",
        "    )\n",
        "    print(f\"[EmbeddingOpeanAI] Embedding gerada com dim={len(openai_emb[0])}\")\n",
        "    print(type(openai_emb))\n",
        "    for i, item in enumerate(openai_emb):\n",
        "        print(f\"{i}:\")\n",
        "        print(type(item))\n",
        "        print(item)\n",
        "\n",
        "    # (c) Normalizar a primeira embedding\n",
        "    print(\"\\n\\n\\n\")\n",
        "    cc.NormalizeEmbeddings(openai_emb[0])\n",
        "except Exception as e:\n",
        "    print(\"Não foi possível gerar embeddings com OpenAI (talvez sem chave válida):\", e)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TC3FnO6STE3s"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bTQoEHv-BVU8"
      },
      "outputs": [],
      "source": [
        "# 3) CHUNKANDO COM ChunkCount (divide texto a cada pontuação final, usando regex, overlap menor)\n",
        "# ChunkCount(const std::string &count_unit, const int overlap = 600, const int count_threshold = 1);\n",
        "count_chunker = cc.ChunkCount(\"regex:[.!?]+\", overlap=10, count_threshold=1)\n",
        "count_chunker2 = cc.ChunkCount(\"regex:[.!?]+\", overlap=10, count_threshold=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "2SeCahSTBVU8"
      },
      "outputs": [],
      "source": [
        "# std::vector<RAGLibrary::Document> ProcessData(RAGLibrary::LoaderDataStruct &item);\n",
        "count_docs = count_chunker.ProcessData(item_struct[0])\n",
        "# std::vector<RAGLibrary::Document> ProcessData(const std::vector<RAGLibrary::LoaderDataStruct> &items, int max_workers = 4);\n",
        "count_docs2 = count_chunker2.ProcessData(item_struct, max_workers=5) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_29mUNwnBVU8",
        "outputId": "c48749d4-6b4e-4bed-b697-c2c95b98763c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChunkCount from 6914\n",
            "ChunkCount2 from 8857\n"
          ]
        }
      ],
      "source": [
        "print(f\"ChunkCount from {len(count_docs)}\")\n",
        "print(f\"ChunkCount2 from {len(count_docs2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "RV2_9DJDBVU8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "Count\n",
            " METADATA => {'fileIdentifier': '1984'}\n",
            "<class 'purecpp_libs.RAGDocument'>\n",
            "<class 'str'>\n",
            "0:  Document(metadata={\"fileIdentifier\":\"1984\"}, page_content=\"Download free eBooks of classic literature, books and \n",
            "novels at Planet eBook.\")\n",
            "<class 'purecpp_libs.RAGDocument'>\n",
            "<class 'str'>\n",
            "1:  Document(metadata={\"fileIdentifier\":\"1984\"}, page_content=\"net eBook. Subscribe to our free eBooks blog \n",
            "and email newsletter.\")\n",
            "<class 'purecpp_libs.RAGDocument'>\n",
            "<class 'str'>\n",
            "2:  Document(metadata={\"fileIdentifier\":\"1984\"}, page_content=\"ewsletter.\n",
            "1984\n",
            "By George Orwell\n",
            "\u0018 1984\n",
            "Part One\n",
            "Free eBooks at Planet eBook.\")\n",
            "<class 'purecpp_libs.RAGDocument'>\n",
            "<class 'str'>\n",
            "3:  Document(metadata={\"fileIdentifier\":\"1984\"}, page_content=\"net eBook.com \u0018\n",
            "Chapter 1\n",
            "I\n",
            "t was a bright cold day in April, and the clocks were strik\u0002ing th...\")\n",
            "-----------------------------------------------------------------------------------------\n",
            "Count 2\n",
            " METADATA => {'fileIdentifier': 'a-christmas-carol'}\n",
            "<class 'purecpp_libs.RAGDocument'>\n",
            "<class 'str'>\n",
            "0:  Document(metadata={\"fileIdentifier\":\"a-christmas-carol\"}, page_content=\"Download free eBooks of classic literature, books and \n",
            "novels at Planet eBook.\")\n",
            "<class 'purecpp_libs.RAGDocument'>\n",
            "<class 'str'>\n",
            "1:  Document(metadata={\"fileIdentifier\":\"a-christmas-carol\"}, page_content=\"net eBook. Subscribe to our free eBooks blog \n",
            "and email newsletter.\")\n",
            "<class 'purecpp_libs.RAGDocument'>\n",
            "<class 'str'>\n",
            "2:  Document(metadata={\"fileIdentifier\":\"a-christmas-carol\"}, page_content=\"ewsletter.\n",
            "A Christmas Carol\n",
            "By Charles Dickens\n",
            "\u0018 Sons and Lovers\n",
            "I have endeavoured in this G...\")\n",
            "<class 'purecpp_libs.RAGDocument'>\n",
            "<class 'str'>\n",
            "3:  Document(metadata={\"fileIdentifier\":\"a-christmas-carol\"}, page_content=\"\n",
            "with me. May it haunt their houses pleasantly, and no one \n",
            "wish to lay it.\")\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"-----------------------------------------------------------------------------------------\")\n",
        "print(\"Count\")\n",
        "list_count_docs = []\n",
        "prev_m = None\n",
        "for i, doc in enumerate(count_docs):\n",
        "    if i > 3: break\n",
        "    if doc.metadata != prev_m or prev_m is None:\n",
        "        print(\" METADATA =>\", doc.metadata)\n",
        "    print(type(doc))\n",
        "    print(type(doc.page_content))\n",
        "    list_count_docs.append(doc.page_content)\n",
        "    print(f\"{i}:  {doc}\")\n",
        "    prev_m = doc.metadata\n",
        "\n",
        "print(\"-----------------------------------------------------------------------------------------\")\n",
        "print(\"Count 2\")\n",
        "list_count_docs2 = []\n",
        "prev_m = None\n",
        "for i, doc in enumerate(count_docs2):\n",
        "    if i > 3: break\n",
        "    if doc.metadata != prev_m or prev_m is None:\n",
        "        print(\" METADATA =>\", doc.metadata)\n",
        "    print(type(doc))\n",
        "    print(type(doc.page_content))\n",
        "    list_count_docs2.append(doc.page_content)\n",
        "    print(f\"{i}:  {doc}\")\n",
        "    prev_m = doc.metadata\n",
        "print(\"-----------------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 0:  Download free eBooks of classic literature, books and \n",
            "novels at Plan ...\n",
            " 1:  net eBook. Subscribe to our free eBooks blog \n",
            "and email newsletter. ...\n",
            " 2:  ewsletter.\n",
            "1984\n",
            "By George Orwell\n",
            "\u0018 1984\n",
            "Part One\n",
            "Free eBooks at Pla ...\n",
            " 3:  net eBook.com \u0018\n",
            "Chapter 1\n",
            "I\n",
            "t was a bright cold day in April, and t ...\n",
            "-----------------------------------------------------------------------------------------\n",
            " 0:  Download free eBooks of classic literature, books and \n",
            "novels at Plan ...\n",
            " 1:  net eBook. Subscribe to our free eBooks blog \n",
            "and email newsletter. ...\n",
            " 2:  ewsletter.\n",
            "A Christmas Carol\n",
            "By Charles Dickens\n",
            "\u0018 Sons and Lovers\n",
            "I ...\n",
            " 3:  \n",
            "with me. May it haunt their houses pleasantly, and no one \n",
            "wish to  ...\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i, doc in enumerate(list_count_docs):\n",
        "    print(f\" {i}:  {doc[:70]} ...\")\n",
        "print(\"-----------------------------------------------------------------------------------------\")\n",
        "\n",
        "for i, doc in enumerate(list_count_docs2):\n",
        "    print(f\" {i}:  {doc[:70]} ...\")\n",
        "print(\"-----------------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUuJZVCbBVU8",
        "outputId": "81a7cc17-567a-4de5-d756-a73e3f84286a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SplitText] Gerei 3 pedaços. Primeiro pedaço:\n",
            "   Este é um texto de exemplo.\n",
            "Ele será unido e fat\n"
          ]
        }
      ],
      "source": [
        "# 4) USANDO ALGUMAS FUNÇÕES DE CHUNKCOMMONS MANUALMENTE\n",
        "#    Exemplo:  (a) Dividir manualmente um texto e (b) Gerar embeddings via OpenAI\n",
        "#    (c) Normalizar e exibir a embedding\n",
        "\n",
        "# (a) SplitText manual\n",
        "text_example = [\"Este é um texto de exemplo.\", \"Ele será unido e fatiado em 50 chars com 10 de overlap.\"]\n",
        "splitted = cc.SplitText(text_example, overlap=10, chunk_size=50)\n",
        "print(f\"[SplitText] Gerei {len(splitted)} pedaços. Primeiro pedaço:\\n   {splitted[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "3x20AwraBVU9",
        "outputId": "ed5ff1b8-f27e-42be-bc97-d92d824459f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Não foi possível gerar embeddings com OpenAI (talvez sem chave válida): {\"code\":\"invalid_api_key\",\"message\":\"Incorrect API key provided: sk-proj-********************************************************************************************************************************************************SkkA. You can find your API key at https://platform.openai.com/account/api-keys.\",\"param\":null,\"type\":\"invalid_request_error\"}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 5) USANDO FUNÇÕES DE EMBEDDINGS MANUALMENTE\n",
        "#    Exemplo:  (a) Gerar embeddings via OpenAI\n",
        "#    (b) Normalizar e exibir a embedding\n",
        "try:\n",
        "    openai_emb = cc.EmbeddingOpeanAI(\n",
        "        list_count_docs, # tem q ser uma lista de string\n",
        "        API_KEY,\n",
        "    )\n",
        "    print(f\"[EmbeddingOpeanAI] Embedding gerada com dim={len(openai_emb[0])} \")\n",
        "    for i, item in enumerate(openai_emb):\n",
        "        print(f\"{i}:\")\n",
        "        print(type(item))\n",
        "        print(item)\n",
        "\n",
        "    cc.NormalizeEmbeddings(openai_emb[0])\n",
        "except Exception as e:\n",
        "    print(\"Não foi possível gerar embeddings com OpenAI (talvez sem chave válida):\", e)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pvjnKx7BVU9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e1w9rbnBVU9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGpWCu2oBVU9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
